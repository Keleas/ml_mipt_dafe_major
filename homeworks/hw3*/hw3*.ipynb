{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дополнительное домашнее задание №3*\n",
    "\n",
    "Это просто вторая часть из [лабараторной работы №3](https://github.com/ml-mipt/ml-mipt/blob/b9f61d59cadbe825f476befa954d75ebbb30c30e/homeworks/Lab3_DL/Lab3_DL.ipynb) с курса ФИВТа\n",
    "\n",
    "Решенный ноутбук нужно загрузить в [форму](http://bit.ly/dafe_hw)  \n",
    "Дедлайн: __24.05.2019__\n",
    "\n",
    "В этой части задания мы научимся генерировать текст с помощью нейронных сетей. Конкретнее, обучим нейронную сеть на сонетах Шекспира и попросим нейросеть написать свой сонет.\n",
    "\n",
    "Генерация текста обычно включает в себя следующие шаги:\n",
    "    \n",
    "1. Загрузка данных.\n",
    "2. Создание словарей слов/символов.\n",
    "3. Препроцессинг данных.\n",
    "4. Обучение модели (нейросети).\n",
    "5. Генерация нового текста.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала загрузим данные. Файл с сонетами Шекспира доступен по [ссылке](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). Кроме того, он находится рядом с этим ноутбуком (`sonnetes.txt`).\n",
    "\n",
    "Базовая предобработка уже сделана: текст состоит непосредственно из поэм Шекспира и названий/номеров глав, все техническая информация удалена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sonnets.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "TEXT_START = 45\n",
    "TEXT_END = -368\n",
    "text = text[TEXT_START:TEXT_END]\n",
    "assert len(text) == 2616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как в этот раз мы хотим научиться предсказывать текст, понизим сложность задачи и приведем текст к нижнему регистру.\n",
    "\n",
    "В настоящий момент переменная `text` представляет собой список из строк. Объедините все строки в одну и приведите к нижнему регистру. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отлично!\n"
     ]
    }
   ],
   "source": [
    "# Объедините все строки в одну и приведите к нижнему регистру.\n",
    "# Результат запишите в переменную text.\n",
    "import string\n",
    "\n",
    "# Your great code here\n",
    "text = [line.lower() for line in text]\n",
    "text = ''.join(text)\n",
    "\n",
    "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
    "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
    "print('Отлично!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделите множество всех символов, с которыми нам довелось встретиться в переменную `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "words = list(set(tokenizer.tokenize(text)))\n",
    "tokens = np.array(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте словарь `token_to_idx` вида <символ>: <индекс> и словарь `idx_to_token` вида <индекс>: <символ>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь вида <индекс>:<символ>\n",
    "# Your great code here\n",
    "idx_to_token = {i:word for i, word in enumerate(tokens)}\n",
    "\n",
    "# словарь вида <символ>:<индекс>\n",
    "# Your great code here\n",
    "token_to_idx = {word:i for i, word in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_idx), \"dictionaries must have same size\"\n",
    "num_tokens = len(tokens)\n",
    "for i in range(num_tokens):\n",
    "    assert token_to_idx[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_matrix(names, max_len=None, pad=token_to_idx[' '], dtype='int32', batch_first = True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        line_ix = [token_to_idx[c] for c in names[i]]\n",
    "        names_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        names_ix = np.transpose(names_ix)\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0da9afbd3567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-53771a8c36bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-bc0014a74312>\u001b[0m in \u001b[0;36mone_hot_encode\u001b[0;34m(arr, n_labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mone_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "one_hot_encode(tokens, len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Комментарий: т.к. у нас всего 38 различных токенов, в этот раз воспользуемся one-hot encoding'ом.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь наша задача - создать и обучить рекуррентную нейронную сеть, которая сможет генерировать что-то похожее на поэзию Шекспира.\n",
    "\n",
    "Для начала воспользуемся классической RNN, аналогичной построенной на семинаре. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, variable containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, variable containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "        # get vector embedding of x\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        # compute next hidden state using self.rnn_update\n",
    "        # hint: use torch.cat(..., dim=...) for concatenation\n",
    "        x_and_h = torch.cat((x_emb, h_prev), dim=1)\n",
    "        h_next = self.rnn_update(x_and_h)\n",
    "        \n",
    "        h_next = F.tanh(h_next)\n",
    "        \n",
    "        assert h_next.size() == h_prev.size()\n",
    "        \n",
    "        #compute logits for next character probs\n",
    "        logits = self.rnn_to_logits(h_next)\n",
    "        \n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return Variable(torch.zeros(batch_size, self.num_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_rnn = CharRNNCell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_loop(char_rnn, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_ix.size()\n",
    "    hid_state = char_rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_ix.transpose(0,1):\n",
    "        hid_state, logp_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keleas/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "batch_ix = to_matrix(words[:5])\n",
    "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "\n",
    "logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "\n",
    "assert torch.max(logp_seq).data.numpy() <= 0\n",
    "assert tuple(logp_seq.size()) ==  batch_ix.shape + (num_tokens,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_logp = logp_seq[:, :-1]\n",
    "actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
    "\n",
    "loss = -logp_next.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in char_rnn.parameters():\n",
    "    assert w.grad is not None and torch.max(torch.abs(w.grad)).data.numpy() != 0, \\\n",
    "        \"Loss is not differentiable w.r.t. a weight with shape %s. Check forward method.\" % (w.size(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "char_rnn = CharRNNCell()\n",
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MAX_LENGTH = 16\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(words, 32), max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    #<YOUR CODE>\n",
    "    predictions_logp = logp_seq[:, :-1]\n",
    "    actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "    loss = -torch.mean(torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None]))###YOUR CODE\n",
    "    \n",
    "    # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    #<YOUR CODE>\n",
    "    \n",
    "    history.append(loss.data.numpy())\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        next_ix = np.random.choice(num_tokens,p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kekest          \n",
      "keks            \n",
      "keking          \n",
      "kek             \n",
      "kekanged        \n",
      "kekrouss        \n",
      "kek             \n",
      "kekirn          \n",
      "keking          \n",
      "keking          \n",
      "kek             \n",
      "kekind          \n",
      "kekshe          \n",
      "kekndale        \n",
      "keks            \n",
      "keks            \n",
      "keknedsy        \n",
      "keksens         \n",
      "kek             \n",
      "keks            \n",
      "kekness         \n",
      "kekger          \n",
      "kek             \n",
      "kekstry         \n",
      "kek             \n",
      "kekth           \n",
      "kekvi           \n",
      "kekne           \n",
      "kek             \n",
      "kek             \n",
      "kek             \n",
      "keknth          \n",
      "keking          \n",
      "kekche          \n",
      "keks            \n",
      "kek             \n",
      "kekele          \n",
      "kekes           \n",
      "kekidess        \n",
      "keking          \n",
      "keks            \n",
      "keky            \n",
      "kek             \n",
      "kek             \n",
      "kekt            \n",
      "kekbs-          \n",
      "keking          \n",
      "keks            \n",
      "kekser          \n",
      "kekts           \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _ in range(50):\n",
    "    print(generate_sample(char_rnn, seed_phrase='kek'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте график функции потерь в зависимости от номера эпохи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your plot code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример сгенерированного текста. Функция `generate_text` отсутствует в коде выше.\n",
    "# print(generate_text(length=500, temperature=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Более поэтичная модель\n",
    "\n",
    "Теперь давайте воспользуемся LSTM слоем вместо классической RNN и сравним результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова постройте график функции потерь от числа эпох. Стал ли финальный loss лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your beautiful code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируйте текст с помощью обученной сети для различных значений параметра `temperature`: `[0.1, 0.2, 0.5, 1.0, 2.0]` (\"температуры\" при генерации). Оцените результаты визуально, попробуйте их проинтерпретировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Text generation with different tempearature values here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь можно оставить свои рассуждения касательно интерпретации результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение и загрузка модели\n",
    "\n",
    "Сохраните обученную модель на диск, затем загрузите ее и сгенерируйте текст. Примеры доступны по [ссылке](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving and loading code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки\n",
    "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Статья Андрея Карпатого про RNN. </a> В качестве примеров рассматриваются задачи генерации Шекспировских текстов, Latex формул, Linux Source Code и детских имен.\n",
    "2. <a href='https://github.com/karpathy/char-rnn'> Репозиторий с кодом по char-rnn </a> (тоже за авторством Андрея Карпатого)\n",
    "3. Полезный репозиторий по PyTorch: [ссылка](https://github.com/spro/practical-pytorch`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
