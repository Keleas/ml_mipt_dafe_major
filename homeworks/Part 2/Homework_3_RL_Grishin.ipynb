{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 - RL\n",
    "Традиционно, Ваш ноутбук должен быть воспроизводим. Не забудьте сохранить Output   \n",
    "Загружать ноутбук сюда: http://bit.ly/dafe_hw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from gym.envs import toy_text\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Tabular Q-learning [30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем алгоритм Q-learning для среды CliffWalking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что из себя представляет среда CliffWalking <img src=\"cliffwalking.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = toy_text.CliffWalkingEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    This is a simple implementation of the Gridworld Cliff\n",
      "    reinforcement learning task.\n",
      "\n",
      "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
      "    by Sutton and Barto:\n",
      "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
      "\n",
      "    With inspiration from:\n",
      "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
      "\n",
      "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
      "        [3, 0] as the start at bottom-left\n",
      "        [3, 11] as the goal at bottom-right\n",
      "        [3, 1..10] as the cliff at bottom-center\n",
      "\n",
      "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
      "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(env.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как награда выражатеся отрицательными значениями, то фактической целью агента является как можно более быстрое преодоление пути от старта к финишу при этом ему нужно не упасть с обрыва."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Традиционно посмотрим сколько очков в среднем за 100 эпизодов сможет набрать \"cлучайный\" агент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 finished after 69 timesteps\n"
     ]
    }
   ],
   "source": [
    "total_reward = []\n",
    "for episode in range(100):\n",
    "    episode_reward = 0\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "#         env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        if done:\n",
    "            print(\"Episode {} finished after {} timesteps\".format(episode+1, t+1))\n",
    "            break\n",
    "    total_reward.append(episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1144.14\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(total_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемо, наш \"случайный\" агент просто блуждает по среде, не пытаясь добраться до цели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним как выглядит реализация данного алгоритма <img src=\"q_learning.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы раелизуем табличную версию Q-learning, создадим структура, которая будет хранить значения нашей функции *Q(S,A)* для каждого состояния и действия. Она пдетставляет собой словарь (*dict*), хранящий в качестве ключей состояния, а в качестве значений массив значений *Q-функции* для каждого действия для данного ключа-состояния."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-значения для состояния-действия (0, 0): [0. 0. 0. 0.] хранятся в списке, по значению для каждого действия\n",
      "Таким обарзом, Q-значение для действия 3 в в состоянии (1,2), i.e. Q((1,2), 3), можно получить вот так q_vals[(1,2)][3]: 0.0\n"
     ]
    }
   ],
   "source": [
    "Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "\n",
    "print(\"Q-значения для состояния-действия (0, 0): %s\" % Q[(0, 0)], \"хранятся в списке, по значению для каждого действия\")\n",
    "print(\"Таким обарзом, Q-значение для действия 3 в в состоянии (1,2), i.e. Q((1,2), 3), можно получить вот так q_vals[(1,2)][3]:\", Q[(1,2)][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала напишем функцию реализующую $\\epsilon$-greedy политику для исследования среды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_greedy(Q, epsilon, state):\n",
    "    \"\"\"\n",
    "    Параметры:\n",
    "        Q: таблица значений Q-функции\n",
    "        epsilon: параметр эпсилон\n",
    "        state: текущее состоние\n",
    "    Результат:\n",
    "        Случайное действие с вероятностью eps или argmax Q(s, .) c вероятностью (1 - eps)\n",
    "        random action with probability of eps; argmax Q(s, .) with probability of (1-eps)\n",
    "    \"\"\"\n",
    "    if np.random.random() < epsilon:\n",
    "        return np.random.choice(4)\n",
    "    else:\n",
    "        return np.argmax(Q[state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также напишем функцию, которая поможет нам оценить, как ведет себя обученный агент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_eval(Q, render=True):\n",
    "    total_reward = []\n",
    "    for i_episode in range(100):\n",
    "        episode_reward = 0\n",
    "        observation = env.reset()\n",
    "        for t in range(100):\n",
    "            if render:\n",
    "                env.render()\n",
    "            action = np.argmax(Q[observation])\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            if done:\n",
    "                print(\"Episode {} finished after {} timesteps\".format(i_episode+1, t+1))\n",
    "                break\n",
    "        total_reward.append(episode_reward)\n",
    "    return np.mean(total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь реализуем функцию обучения агента (обновления значений Q-функции) с использование функции, реализующей $\\epsilon$-greedy политику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(env, num_episodes, discount_factor=1.0, alpha=0.5, epsilon=0.1):\n",
    "    \"\"\"    \n",
    "    Параменты:\n",
    "        env: среда Open AI\n",
    "        num_episodes: Количество эпизодов\n",
    "        discount_factor: фактор дисконтирования\n",
    "        alpha: константа обучения\n",
    "        epsilon: параметр эпсилон для ϵ-greedy политику\n",
    "    \n",
    "    Результат:\n",
    "        Таблица с оптимальными значениями Q-функции\n",
    "    \"\"\"\n",
    "    q_values = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "\n",
    "    episode_lengths=np.zeros(num_episodes)\n",
    "    episode_rewards=np.zeros(num_episodes)\n",
    "        \n",
    "    for i_episode in range(num_episodes):\n",
    "        if (i_episode + 1) % 100 == 0:\n",
    "            print(\"\\rEpisode {}/{}.\".format(i_episode + 1, num_episodes), end=\"\")\n",
    "        \n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        reward_sum = 0\n",
    "        \n",
    "        while not done:            \n",
    "            # Choose action        \n",
    "            action = eps_greedy(q_values, epsilon, state)\n",
    "            # Do the action\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            reward_sum += reward\n",
    "            # Update q_values       \n",
    "            td_target = reward + 0.9 * np.max(q_values[next_state])\n",
    "            td_error = td_target - q_values[state][action]\n",
    "            q_values[state][action] += alpha * td_error\n",
    "            # Update state\n",
    "            state = next_state\n",
    "\n",
    "            \n",
    "        np.append(episode_rewards, reward_sum)\n",
    "    \n",
    "    return q_values, episode_lengths, episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = toy_text.CliffWalkingEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode 100/500.\r",
      "Episode 200/500.\r",
      "Episode 300/500.\r",
      "Episode 400/500.\r",
      "Episode 500/500."
     ]
    }
   ],
   "source": [
    "Q, episode_lengths, episode_rewards = q_learning(env, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished after 13 timesteps\n",
      "Episode 2 finished after 13 timesteps\n",
      "Episode 3 finished after 13 timesteps\n",
      "Episode 4 finished after 13 timesteps\n",
      "Episode 5 finished after 13 timesteps\n",
      "Episode 6 finished after 13 timesteps\n",
      "Episode 7 finished after 13 timesteps\n",
      "Episode 8 finished after 13 timesteps\n",
      "Episode 9 finished after 13 timesteps\n",
      "Episode 10 finished after 13 timesteps\n",
      "Episode 11 finished after 13 timesteps\n",
      "Episode 12 finished after 13 timesteps\n",
      "Episode 13 finished after 13 timesteps\n",
      "Episode 14 finished after 13 timesteps\n",
      "Episode 15 finished after 13 timesteps\n",
      "Episode 16 finished after 13 timesteps\n",
      "Episode 17 finished after 13 timesteps\n",
      "Episode 18 finished after 13 timesteps\n",
      "Episode 19 finished after 13 timesteps\n",
      "Episode 20 finished after 13 timesteps\n",
      "Episode 21 finished after 13 timesteps\n",
      "Episode 22 finished after 13 timesteps\n",
      "Episode 23 finished after 13 timesteps\n",
      "Episode 24 finished after 13 timesteps\n",
      "Episode 25 finished after 13 timesteps\n",
      "Episode 26 finished after 13 timesteps\n",
      "Episode 27 finished after 13 timesteps\n",
      "Episode 28 finished after 13 timesteps\n",
      "Episode 29 finished after 13 timesteps\n",
      "Episode 30 finished after 13 timesteps\n",
      "Episode 31 finished after 13 timesteps\n",
      "Episode 32 finished after 13 timesteps\n",
      "Episode 33 finished after 13 timesteps\n",
      "Episode 34 finished after 13 timesteps\n",
      "Episode 35 finished after 13 timesteps\n",
      "Episode 36 finished after 13 timesteps\n",
      "Episode 37 finished after 13 timesteps\n",
      "Episode 38 finished after 13 timesteps\n",
      "Episode 39 finished after 13 timesteps\n",
      "Episode 40 finished after 13 timesteps\n",
      "Episode 41 finished after 13 timesteps\n",
      "Episode 42 finished after 13 timesteps\n",
      "Episode 43 finished after 13 timesteps\n",
      "Episode 44 finished after 13 timesteps\n",
      "Episode 45 finished after 13 timesteps\n",
      "Episode 46 finished after 13 timesteps\n",
      "Episode 47 finished after 13 timesteps\n",
      "Episode 48 finished after 13 timesteps\n",
      "Episode 49 finished after 13 timesteps\n",
      "Episode 50 finished after 13 timesteps\n",
      "Episode 51 finished after 13 timesteps\n",
      "Episode 52 finished after 13 timesteps\n",
      "Episode 53 finished after 13 timesteps\n",
      "Episode 54 finished after 13 timesteps\n",
      "Episode 55 finished after 13 timesteps\n",
      "Episode 56 finished after 13 timesteps\n",
      "Episode 57 finished after 13 timesteps\n",
      "Episode 58 finished after 13 timesteps\n",
      "Episode 59 finished after 13 timesteps\n",
      "Episode 60 finished after 13 timesteps\n",
      "Episode 61 finished after 13 timesteps\n",
      "Episode 62 finished after 13 timesteps\n",
      "Episode 63 finished after 13 timesteps\n",
      "Episode 64 finished after 13 timesteps\n",
      "Episode 65 finished after 13 timesteps\n",
      "Episode 66 finished after 13 timesteps\n",
      "Episode 67 finished after 13 timesteps\n",
      "Episode 68 finished after 13 timesteps\n",
      "Episode 69 finished after 13 timesteps\n",
      "Episode 70 finished after 13 timesteps\n",
      "Episode 71 finished after 13 timesteps\n",
      "Episode 72 finished after 13 timesteps\n",
      "Episode 73 finished after 13 timesteps\n",
      "Episode 74 finished after 13 timesteps\n",
      "Episode 75 finished after 13 timesteps\n",
      "Episode 76 finished after 13 timesteps\n",
      "Episode 77 finished after 13 timesteps\n",
      "Episode 78 finished after 13 timesteps\n",
      "Episode 79 finished after 13 timesteps\n",
      "Episode 80 finished after 13 timesteps\n",
      "Episode 81 finished after 13 timesteps\n",
      "Episode 82 finished after 13 timesteps\n",
      "Episode 83 finished after 13 timesteps\n",
      "Episode 84 finished after 13 timesteps\n",
      "Episode 85 finished after 13 timesteps\n",
      "Episode 86 finished after 13 timesteps\n",
      "Episode 87 finished after 13 timesteps\n",
      "Episode 88 finished after 13 timesteps\n",
      "Episode 89 finished after 13 timesteps\n",
      "Episode 90 finished after 13 timesteps\n",
      "Episode 91 finished after 13 timesteps\n",
      "Episode 92 finished after 13 timesteps\n",
      "Episode 93 finished after 13 timesteps\n",
      "Episode 94 finished after 13 timesteps\n",
      "Episode 95 finished after 13 timesteps\n",
      "Episode 96 finished after 13 timesteps\n",
      "Episode 97 finished after 13 timesteps\n",
      "Episode 98 finished after 13 timesteps\n",
      "Episode 99 finished after 13 timesteps\n",
      "Episode 100 finished after 13 timesteps\n"
     ]
    }
   ],
   "source": [
    "score = q_eval(Q, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episode_lengths);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episode_rewards);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Approx Q-Learning [70%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам предстоит научиться сажать космисеческий корабль в среде [LunarLander-v2](https://gym.openai.com/envs/LunarLander-v2/)\n",
    "\n",
    "\n",
    "Используйте Approx Q-Learning и repaly buffer\n",
    " \n",
    "Для того, чтобы получить полные баллы, ваш корабль должен садиться 10 раз из 10.\n",
    "  \n",
    "Если меньше, то баллы будут снижены пропорционально. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque, namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape:  (8,)\n",
      "Number of actions:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keleas/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(0)\n",
    "print('State shape: ', env.observation_space.shape)\n",
    "print('Number of actions: ', env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingQNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, seed, fc1_size = 64, fc2_size = 64):\n",
    "        \"\"\"\n",
    "        state_size (int): Dimension of each state\n",
    "        action_size (int): Dimension of each action\n",
    "        seed (int): Random seed\n",
    "        \"\"\"\n",
    "        super(DuelingQNetwork, self).__init__()\n",
    "        self.num_actions = action_size\n",
    "        fc3_1_size = fc3_2_size = 32\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_size)\n",
    "        self.fc2 = nn.Linear(fc1_size, fc2_size)\n",
    "        \n",
    "        # The one that calculate V(s)\n",
    "        self.fc3_1 = nn.Linear(fc2_size, fc3_1_size)\n",
    "        self.fc4_1 = nn.Linear(fc3_1_size, 1)\n",
    "        # The one that calculate A(s,a)\n",
    "        self.fc3_2 = nn.Linear(fc2_size, fc3_2_size)\n",
    "        self.fc4_2 = nn.Linear(fc3_2_size, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        val = F.relu(self.fc3_1(x))\n",
    "        val = self.fc4_1(val)\n",
    "        \n",
    "        adv = F.relu(self.fc3_2(x))\n",
    "        adv = self.fc4_2(adv)\n",
    "        \n",
    "        # Q(s,a) = V(s) + (A(s,a) - 1/|A| * sum A(s,a'))\n",
    "        action = val + adv - adv.mean(1).unsqueeze(1).expand(state.size(0), self.num_actions)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 32  # minibatch size\n",
    "GAMMA = 0.99  # discount factor\n",
    "TAU = 1e-3  # for soft update of target parameters\n",
    "LR = 5e-4  # learning rate \n",
    "UPDATE_EVERY = 4  # how often to update the network\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\" Fixed-size buffer to store experience tuples \"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"\n",
    "        action_size (int): dimension of each action\n",
    "        buffer_size (int): maximum size of buffer\n",
    "        batch_size (int): size of each training batch\n",
    "        seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\" Add a new experience to memory \"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\" Randomly sample a batch of experiences from memory\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return the current size of internal memory \"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\"\n",
    "        state_size (int): dimension of each state\n",
    "        action_size (int): dimension of each action\n",
    "        seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = DuelingQNetwork(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = DuelingQNetwork(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience \n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn_DDQN(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "        \"\"\"\n",
    "        Returns actions for given state as per current policy\n",
    "            \n",
    "        state (array_like): current state\n",
    "        eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"\n",
    "        Update value parameters using given batch of experience tuples\n",
    "        \n",
    "        experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n",
    "        gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # update target network\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)  \n",
    "        \n",
    "       \n",
    "    def learn_DDQN(self, experiences, gamma):\n",
    "        \"\"\"\n",
    "        Update value parameters using given batch of experience tuples\n",
    "        \n",
    "        experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n",
    "        gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        Q_argmax = self.qnetwork_local(next_states).detach()\n",
    "        _, a_prime = Q_argmax.max(1)\n",
    "        \n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().gather(1, a_prime.unsqueeze(1)) \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # update target network\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)  \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"\n",
    "        Soft update model parameters\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        \n",
    "        local_model (PyTorch model): weights will be copied\n",
    "        target_model (PyTorch model): weights will be copied\n",
    "        tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -202.72\n",
      "Episode 200\tAverage Score: -106.66\n",
      "Episode 300\tAverage Score: 6.51751\n",
      "Episode 400\tAverage Score: 96.06\n",
      "Episode 500\tAverage Score: 109.56\n",
      "Episode 600\tAverage Score: 156.35\n",
      "Episode 700\tAverage Score: 211.78\n",
      "Episode 714\tAverage Score: 220.21\n",
      "Environment solved in 614 episodes!\tAverage Score: 220.21\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEKCAYAAAA8QgPpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXecXFX5/z/PzGxPr4S0BZIAoUNCIBAITarEDuhPyldAmqBiAUEQBUFBBRWFUKSDICooPSFAiAmkQEJISLKEVNLrZpPdnXJ+f9x77px777ltys7M5nm/XvvamVufaec5Tz0khADDMAzDRCVWagEYhmGYyoQVCMMwDJMTrEAYhmGYnGAFwjAMw+QEKxCGYRgmJ1iBMAzDMDnBCoRhGIbJCVYgDMMwTE6wAmEYhmFyIlFqAYpJnz59RGNjY6nFYBiGqShmz569UQjRN+i4Tq1AGhsbMWvWrFKLwTAMU1EQ0fIwx7ELi2EYhskJViAMwzBMTrACYRiGYXKCFQjDMAyTE6xAGIZhmJxgBcIwDMPkBCsQhmEYJidYgTAMw5Q56YzAszNXIpXOlFoUG6xAGIZhypxnZq7AT56fh0enh6rv6zBYgTAMw5Q5za0pAMD67a0llsQOKxCGYZgyJxEjAEA7u7AYhmGYKFQnjKE6yQqEYRiGiUJV3FQgKVFiSeywAmEYptOwvTWJ1mS6aNf/36cbcedrn0Q6pz2VwSsfrYEQuQ/+0oWVzLAFwjAMUxQO/sXr+NK906znt/53AcbfOaVg1//mA+/h3imfRjrnL2814fIn52DSwvWex6jK5Q9vLMbfpn3m2G/8T6aDldDjM5Zj6YYdkWTMlU69HgjDMLsfn6xtth4/+O5nPke6uf2VhVjw+Xb8+NR9cfCgHnnJkc4IfOneadiysx0AsGLzTu1x81dvw1l/ehdPXjwGxwzrg3smLwEA9Otai2OH90H3uirL8kim/C2QTEbg5/+ej+51VZh78xfykj8MbIEwDFMytu1KovG6l/DsrJWufW2pNHa1u91RQgjMXr65KPLc//ZSTF2yEWf/eRqa1jd7HnfFk7PR3Jr0vdaOthQ+Wr0Nq7bsAmC8Vh1vLTIsk3ebNtq2X/nUHPzsXx8ByCqOlMaF9fj0ZXhjwToAQNo0VbzuVWhYgTAMUzJWm4PrwxpL4cS73sb+N73q2v74jOX46l+nY/LCdUWVbe22Ns99L3+0Fn9561M0XvcSXv94rfaYdMbubtruMajLwb57XZVr3+Yd7djRlsKupKE42jUurJ+/8DEueWyW9p7FhhUIwzAlI2aOQLr48uqtu7TnLN3QAgBYvknvEtKRy8DanvYPxi/fZMhx/ztLAQCbW9px3fPzLKupLWU/PxcF0qO+Cgfe/Bp+86oRuE+mMnhw6lLc/vJCAHAlDGTyCNTnAisQhmFKRoyM7KJF65rReN1L2GrGC8KcE2WwdA7mYWgPiDd0qTFCyC1tRpX4715fhGdmrsSvzcG9LWk/f7vi8nrhw9W49b8LAAD/+mA1AKBrrTsk/cp8u3WTymTw33lrMPkTw+01/s63HPtZgTAM04lYvqkFq7borQWpDCRLN7YEXi8RN86JYlW0JqOnv7YFKBBZ0yfbjEiF8/iM5di6s91VNS6PA4BrnvkQD777Gba3Jm2ZVUGvqTWZwfJNLZZCXOtobRKk9AoNKxCGKWNWb92FB6cuLbUYofjWgzPwrQdnADAC3Z+bLqjj73wLx/5Gn0obI+dz0h6nOybKbFtXG/K1v/4Plz0+G0IIvLFgnWvw/suUT/GLFz/2vGbaDGjvMC0Q9fy2VMZlgeiqyNUkgYzQy6myZlsrtuxMojWZcSUYvLVoPUbdOsn3/ELDCoRhSswrH63BzvaUdt8lj87CrS8t9IwHlBPTmjZhWtMmAMAj/1uGsXe8iU/Wbvc9x6kwnAoFAH703FxMWrDOdYwQAu8u2Yh121tddQ+bdtgD4DprYtbyLXj147V4fs5qXPLYLPx9pj0TbNG6Zjzyv2WesksFJhWIqtCS6YzLbabrY6VaDJmMwK4ABbLRfF1tyTQue2K2bd+vTJdYR8IKhGFKyNyVW3H5k3Nwy4v6H78cUNqKWF1dDKQiCQp0Ow0OnQXyj9mrcPFjs6zBU1Zlz1y2Bf/vofcw5teTceLv3rbN3o9wzMRbk2ms3LwTjde9hDkrttj2zV+9DQCwdZc+/vL49GXa7dLikEWAqgWyaUe7FfiW6NqQSOUDAA9P+wx3T1qsvZeT7a0pvL14g23bpxvs7j8/66lQsAJhmBIii8w+36a3MKri5dmFNRhjsAxySTnj4ETA5IXr0HjdS65jpXsmZiqQDc12K+OtRfYBtTWZtpoQtibTeGeJsf+5Watsx8nAfaum5gQw0mR1SIvD6lOlfEb3TF6CmcvsimrRumbMXGavX1HrNeat2oYnZqzQ3isXgqy/QsAKhGFKiAygVsf1P0U5AHZ0cDRf5GQ8KKLhzKSKEQUumhT3yMJyunQmL1xvvW9tqYxNWanvZ9IUdt1277oPAK5eVmmHAlEtEK/4zNfvm46m9Vl329adwQV/N501MvAYHT3qqnM6LwqsQBimhMhZq8wsciIVS+UpENMCUUaYXe1p/PQf87C5Jesqcg6zRMCgnnW+15YWSFAW75VPzbEeq+4tItiqyKVicGY0OXHeTyoJ+dklFaVR7fF5AkZvLMk2D7eZSq+G3BRBj3p3XUmhYQXCMBq2tyY9U08LgRACmYywFEiVxgJR178O48J6b+kmZIpUB7Bm2y6s9OjlpEMOtqS4sF7+aA3+PmulVQRnHGeXd/mmnfhwxVbfa8dj0etAWpMZW5B5u5JSm7YsEG8F0rS+2XU/mYUlP7uNiktti59loVzGywK595uH49DBRi+uXBVBd1YgDFMazv7Tu56pp2G5d0qT1pcPABPunYb9bnrV14V1yh/ewRxzMA2yQN5ZvAHnTJyBB98tTsrv0be/iXG/Dfd+ZDLCCvCqMZBeXYyZtDrTd+qA7z4+GwvWePvul21s8XRh+bFic4uViUWwWyA7zdiHToFcetzeAIDn56x2WUsyUUB+dmuUOJZqZTn5p1k4CAC/e10fNN+rTwOev3wsltx2OnrWZy2Qbx81FCfv3891/NePGOTaxi4shikRyyK0yfDiztcWATBqOZwV1vNWbUN7KmNZGZYbJJ2xlMVnSlFdkAJZb85+P1nj3QCw0Mxfvc2WRST5z7zPrceqI6erWbm9Xok1RDWYxt/1lmWBROnaoRYSrm9uwwsfZmWUleROq+H1HxyHn52xP2oSMWQywlNhJeKE1mTadv7GHf7xFImXZVlXHUc8RqiKx9DNbHFy0MDu+NWXDsQRQ3u5jm/s0+Daxi4shqlgaquMn9cxd7yJo26frD2m3eHCGvebKRhx4yuex3khg+1tHZSt1ZpM46w/vYvLHp/t2rdmW3Ymn1YGXfnIZoG45vXBSAWSzrGVyRsL1uEhpXmjTgkCwNDe9db9MkJ4Kqx4jCylOKxfFwD2qvNckN8dAGjsXY9rTxmBiecfAcDu2pRUxQkvXX2sbVt9dTwvGcLACoRh8uCDFVtw2C9f1/Zwqq/O9jbyaqUhq4mlAvEK5Mqq5v/O+xzrm93HyKCt13oRza1m23RHsdzUJRuwdpt/8FiHDCA7ayoAe9PAlNKmQw7A23YlrdqLXBbYk4WEqRCLK0mcVeEqXtch036KESGd8bd4pIL/xqisK+mQQd1Dy+ekrio7+BMRvnfScAzobiQX6DK89h/QDd1q7RZHTaL4wzsrEIbJg3unNGHLziRmLtuCTEZgmeJ2CjMDlDPVhK4EW6EtlUFrMo2rnvoA502coTki6wLTIf37971jX03v2w+9jy/++V3X8fve+EqoFio729PutuVKfCGtaAg1YH7Wn95FOiNytEBMaytCZprfsV4pt/IjiZERb/GSVYjsa1MH/rrqOK4+cVhoGVVqq7y/Oxcd04gG87vVp0s1pl13IsYN72tZZhJdYkahKZkCIaLBRDSFiBYQ0cdEdI25vRcRvUFES8z/Pc3tRER/JKImIppHRIeXSnZm9ySVzrhaZMiBOyME/vJWE8bf9RaWrDPiEA3VwQt+Sl95UCygLZW2ZsDOimMgOwN2uro2t7Rj5ead2mI3Oeg5C/KM+2Vw60sLMf3TTVp51KHqj+YKepLtu7LuG3Vwdr7EbbuSkeIY1r1Jyhi+Ot+vx5RXA0OZQRaLkZE15yFrRtlXowz8NYk4vn10Y2gZVfyshx711XjwgtEAjDqigT0My8Q5CenUCgRACsC1QoiRAI4CcCURjQRwHYDJQojhACabzwHgdADDzb9LAfy140Vmdmdue3khjrh1ElraUnhw6lLMWLrJmqW+t3Qz7jIzalaZfavqQlggshJdt9KcSmsy4ztbl0F2Z7uMo26fjHG/nYKEOZhId82MpZvwzzmroUO1FM57QGft2JXBg1OXWkoTcFogbheWZMvO9pwUiAxmR6mNeW72Ks99Xgoka4EQMgI48ObXPOWRMtXaFEhM29srDBRQwS+tWzUesltZIEKINUKIOebjZgALAQwEMAHAo+ZhjwL4kvl4AoDHhMEMAD2IaEAHi83sZqiDqUxNXb11F259aSHOnTjDSlN9eNpnrnOcLix1kJVIF9Zj05f7LpH6zuINthmwrKV44cPV+O+8z7MV1w4LpF1JXQWyFsi5E2fg2ufmuo4DwmVGqe9LS3sap/zhHeu5mo1ki4E4FOCWlnZ8tim4fbuTG/4135C5QAkDXi4sywIh/5RhIbL7q5RBvKYqHqq7cC401BjfLbV4MRGzD+dVPsWMhaIsYiBE1AjgMADvAegvhFhj7loLoL/5eCAANQK4ytzGMEVDHVsGdK8FYF8pL6b5BUljwqlA1EFWombrHPSL1z3lmLdqK7714HvW8/vfWYrWZBrXPPMhrnrqA7Sb7hxdhg6QtRg27mjHFk2Ngmz8155yd5HV4adk1MaPttm9ywJJ4uqnPwi8lxeFWnwvHWD9EZGnAiGSMRDjeUxVIIlY0RRInekeVd/feLzjLZBgJ22RIaIuAJ4H8H0hxHbVdBNCCCKK9DUhokthuLgwZMiQQorK7IakMhnEY4Yi2KOb4WtuWpftZaRzNcjBRrdPCGHbHtYN09KextyV9grtT5UW5nI2Li/92cYWPKAEwdUK9Yma4Phi0zo64a63QrWOd1aQq6jxBnV270yX1SmyUhC0iFOcyDNbrCoes6X4xokspVKTiIEijuFXnTAsVBNEGURP2yyQ3UyBEFEVDOXxpBDin+bmdUQ0QAixxnRRrTe3rwYwWDl9kLnNhhBiIoCJADBq1KiOXd+R6XSoA0dPszBrpdLiRDe/9GskmM4IW9+rZC55rCY7le6xWVeVce0T7nrL87y4RrFJa0mnPFTl8+r8NTjtwAG+s381ZVmd3V/qqBnZ7uOy60jSGYHqeMzTJeZ0YQ3tXW+1qa+Ox2wurFjMeH9TQqA2BxfWj07dN9RxuviaU4FUJzqxC4uMadhDABYKIX6v7HoRwAXm4wsAvKBsP9/MxjoKwDbF1cUwRUFXCKe2vNANEP+c4x2wdfrboyzL6uTr9023Hsu4g5erRd2uC+w21HjPJdWB9bIn5mD11l2+RXytKb0F4sS5ol6pSAthFWLqIDOILjnzoGzotToRswXRicj6TjiD6NIFWghk+xS11mS3CqIDOAbAtwGcSEQfmn9nALgDwClEtATAyeZzAHgZwFIATQAeAHBFCWRmdjPSmvWq1bbfusH49QXrPF08lztajnsVsf1XaQcSBllZ7VUHoiqqmEZov5oVZw3FMXe8iSdmeLdct7mwfIr9dpbJIlnpjPANOMdidpedOlBXxQ3lIt9edUJRk7BbIK9+/7iCyUxEeOWacXjsO2Ns21Q6tQtLCPEuvJcLOElzvABwZVGFYhgH6kxbptpKC6QqTp7plkmPgXPKog22QLdX+u5VT+UWXN7Q3OZatAiwKwGdC8tvoP/KX6a5tt09aYnmSPe9/CyQFo8WIh1NKuNvgcQcQXS7AokhlU5bCiZGWbdkTVXMtuJi97oqfGFkfyxZv8PW5yxX9h/QzXd/Z7dAGKbsUWfuzrbfNYm4a0lWiV9dh9qNNUo7jjBs2Zm0ubYk6qCus0D8lp7VFS76IQQwZi+j4Z9zWVcVrx5UHY0QCFQg6sekKuDqRAwCdgtE6pqaRMyKSUkmnj8KD5w/qlCi++K1SFkhYQXCMD6oCkRaFXJTIk6eQVIvCwQAfvKPecpxHdP8UE2tfeFDdwHh9KWbPFvP50LvLsGtxHfk2XCwkPjN1p1BdDVdtjruiIEo5xkuLN29ih/cBoCqzhxEZ5hKQHVh6QLeXj9Rr3oM1/WLtACUE9UCWaykIReLmkRwFX6hLJCrTxqe9zX8ZuuGVaEoEIcForZ6J1sMRF8HUqzaECfswmKYEqOmsDr9+ZmM8BwM/Hz/KskCKpCePus/+PWCKgZh3CeFUiCHDemR9zX8ek/FHHUgzhiIAKwUPdXiqErEtC5OnQuxGAQ16CwErEAYxgd7DMRuVQgBzxhIMp0J1RIkrKUShjqfDq43v/hxwe4TBr+YgqRQLqxCzOj9ZutEQJNStKnerzoeQ3NrCr96yWgtoyqHREyfZKFLYigGQf20CgErEIbxQbUknAHvjKOq3HZeWvhWa2evkZ98Kn7NG9f4rPnx2P8dWTghTEIpkAJZIM6J9gVHDw113j59s6v4JfzSeInQtH6H9lj5Oheay/Cqsngptv7davBdc6ncSocVCMMoLFnXjKOV1QMzwseFJfR1IMaxmdBrdhcqW0anQI4Y2jPwvH3MVfT8iOoNCaNACpVA4ByoR+7pn94KAJN+eBxu/dJB1nNnI0IVZ4Geej+n5aJOKJznqcdcf8b+gTJWAqxAGEbhvreX2pdk9YuBCOHjwhIIm6HrNdBERefC8nNrSbrVBpeDJSIquTBKMWycKAjnZ6CzCiccuqft+ZBeDbZWH36fgfNyamzB2S5EVS4dEYPw4s1rj++Q+7ACYTqEcydOx4tzo1VXlwJnsDkoBuIZRA/pwgL83SdRqNMsYNXSrncTqQH3MEqmKuJgWJ2I4d5v+q/5VqgMNOdn4JR0cK863HPuYY5z7IrG7+U51zdX4xxORWlzYZVAgfxywgEAgD3NRaaKDSsQpkOYsXRzXq27Owo/BeKMgbSnM3hsur6lRzKTCT1AFirdsl6jCEY39gq8p5d10a9rjfU4qpXUUB0PVIyqBfKbrx5k2xcl/us81KlQdHo8RvYaHr9Pylkxb7dAHC4sRZqOCparnH90I5bdcabvkriFhBUI06lZsWknDv/VG1i52bvSWqXVsRZG2icG4kcqLULHQArl6tDFQPp3q8WRe7mVSBiFoEofdTa9Z4+6QDeWrT+XY7ANO/heOLbRJZtPOMOCyG4t+H1Uzo/dmcbrvG5YOZ6/fGyQmGUPKxCm6IR15RSDf8xZhc0t7Xjep0OuitqKHMgOcumMwOzlW0LfN5XJeK4h4aRQFohu1hkj4K6vHaLZHkKBeLTvCMOePeoCLRDbYkguJRB8v4W/PA03nTXS5X5ytg/Rff1IY4Ec2dgLP9a0U3d+f/2C6Oq+oPdMripYybACYYpOCfVHZJwtxuUgd++UpkjXiWKBFDOIHiPCkN717u0hfvnd6rIxlagWyKCedb6ZTU6c78HZh+zpcWSWuuo4Yppai1w8R0IIPHvZ0fjWGPcidM5PUZXVWYCovuSgz7WjKtKLCSsQpuhUkP5wubBkJbpzNcAgUpmM75oZKoUKoutasnsN/GEGr8uO38d6HNUCaahJROr5pA62y+44EyP6B6cWS1xB9JCy6t4DvxUms+dlH/tZIEFKt4RJWgWDFQhTdMLOxDuS+97+FLe9tMC1vc3pwjJl3xWxFUgyLUIXCVZFmKn7oYuBeA1SToVw45nuuoS6qjiGmTUiUQe7GFEk15xTHn0PKa97RRIte55GPN21nF9f8nVhZR8HKd2OqBQvNqxAmKITVn88P3sV1mwLXo+7EDLc8coneGCqsQjTwjXbLVeVMwtLBs6jKpBUWtj6aPlRsDReDxeWDufseHj/rr7nRnVhxSja63IFwnUtQEJaU2FjbrYYiGZBKIlzAqQe4dSRYQoJddepVFiBMEVHhHBi7WpP49rn5uK8iTM6QKIsn6zdjtPvmYq7Jy025EjqXVhRSxaiVKJHLdLzQmeBeM2CnWObbqyLUXaQixqnobwtEP019feKJJr2HvKz0r1O58eoKhlX/MXjOP39K1+FsAJhik6YcVQuwPS5T88mAJi0YB3uf/vTyDJ4/VbXm8vTfrDCiHE4az2kZRLVSEimRfg6kAI5w3UxEK8qaufg5RUPED77g4iSnuwcuHUDubcLy/8+XhYJaSwQ3aWc56vHOI+PRbBAWIEwTAF4e/EGHPSL1wEEVydf/Ngs3P6K9yp3fmzblcSPnptra+In75a2LA29AolaNZ1KZ0K77nLJwvrKYQNd23RpvF7psTEi/O3C0VYtgl6BKOflMNZFsUCcLiydteE14OZugahpvMK1TeL86P0G/igKpBPoD1YgTPFxDspCCDwy7TM0tyYBAP9RWpzk095iwr3T8N3HZ3nuf3DqUvxj9io8+r9l1rZdZqsPKaPz7jKInsoInLhfP1fFtBfJTHHTeHVXDhMDka6ieIxwwn79rGaLehdW+MFQRxQF4rRWdPfzdscFWCAe23VnhYmBqCe6A+zZx4EWSCdIwwruosYweeL8kc1Yuhm/+M8CfLhyK+4+97DQweZFa5t9989duRVzffbLugR1db6WNiPmsXzTTmxuaXcNFlK0dEYgESPEQ2ZMbW1pd6XxxmOkX9WwQONIGBeWHNTc1dt6l5F03+TkwooSRA8VA/E6N4pU+ntmg+ju4/xiIK5rKhcIzMJSHv/twtGoqaq8+TwrEKboOIfM6Us3AQA27DDiD2Fn6qfe/U7oe366YYfLpSMHNLWN+E7TAlm7vRXj75ziGiyEYoEk4hTar79yy07XtarjMezKZIP0xlrbhfOFa4Poruwm+//sdn+XUS4yRklPDiOPX3v0XFBPy8ZAomVhuavUlccBL199jSfs18//4DKl8lQeU3GoP7JMRuCPk5cAyAasg9qePz5jOT7fGi2996TfvY1j7nhTkSHbOTWpWCBq65LtmhXy5OBhWCCxUK6cXg3VWLl5l8vacDbek9cqVD1AKBeWec9wWU/K/hxGiigWiPPYKGuJBzVP9JqfqNaCX6agu5DQbbno9gUH0X13VwRsgTBFRx1HX5m/1nqc8ghcq2xobsPP/z0fT+7hrlNQUZeGdbYjkcjK6IemfWZtaw9Y1OgHf5+LWcu2IJXJIBELtkBiBBy9T28sXLPd9bpcnVuJAIicBhLdKWEKCaULLkwWVkzJwsqls2ykILqHolPxUrS5u7Cyj/2MYOcum+Xis48LCRmmECi/siufmmM9loO+XwxEDvDbdiV9byFjGQCw0XSNqRABVeYArg4W7angjodPvrcCKzfvQjxGgbNKAaAmHjPWRHdaII4BVQ4wubiHdO9YfZV7Pui8tpXG6/jl69NmFRdWTkH03NN4dW+Jlz7K1QUY9jy/QLnbvRX+PesMFggrEKboeLkHkumse8gL6W4K+rE3t2UVjG6tbdWFpXKP6U4LQyJOodwy8RghrWll4my8ZwW0CzSQ1Fa7X5+nCyvEgG0aSNrrhCHKDDuMBZJrGq/X988Wy/C/hOM8nyD6bmaBsAuLKTpe7oF0iCpv2dwwaOBWlYZzASBJvsHqeIgsLIJRWa4riHS7sOT//AeS2qqYNmjt3CSfhyskzD4u9uJIfuuO+23TbQ/T+QCwv+9R+rX5ub64mSLDFBivn2bSrD73+/HKIHfQALZDCYA3axQIkX1xqK4h1gF3kojFAuUQ8K7A9gqiF2IgqauKawcsp3LycpsFu7Dyl9EPr2wxldGNPbXnBlogXkH0kDEQ9/3U4LvzmuGD6J3BAmEFwhQdLwUhs7C89rel0vj7zJUA3LM5Z/pkc4AFIoQ91nLlCcNCSG4nTAxEHqfDvX527jEQJ2HWNQfUSnTHdo0ItiB6kafLbpea/fkbPzgO137BvdgTUJgYSBQXll3xOGIg6noggb2wIty0TGEXFlNUzvrTVMxfvV27L6hNyG9eWYSn318BwP1jTJt1GZInlLXJVWvkj0qMQ7VA+nfLrvcdlkQsXAzEK3jstEDyUSDOgatWk4GlQ61E18li3+a/v5A4P1/n3Yb37+rZqdkpWlhrItfX5Hca98JiyoItLe2YcO80rNoSbi3vUrK+udXVBh0wZvxeygPIFvR5/eBXKq/daYGoymDl5p2Y/Ml667k2iA5YyggA+nWt9ZTLi/AWiP5n5UxrlU8LMY7IKvRvjBqE4f28F2PKus3CxECUGXruHWZCEWSBAOFjIABw7zcPtx57tjJRP44IL9DvfbEF0bkXFlMqXvhwNeau3IqJ7ywttSiBHHnbZFzymLsH1d4/e9n3vFSABaLWdjjjCv/3yEzLVdXmWEVQp0BmL99sKbNTD+iPIb3cy7wGEaYORCerxGmZFMOF9duvHeK7HKy0oKIG0cMGpnPF1UxRc4x3KxP3jjMPHhB4T/WsKC3Y1Pv5FRkGfVXYAmGKRqUE2OTgP3XJRtv2pvU7As+16kAcP8Lj75yCx6YvsxQM4B5gpjVtwgE3v4aZyzajWXFZ1VXFsaWl3XWvdduztSF3ff0QlzspDLEYoSYR7Crymnk61wjPKhDgtAP2iCyPiq4Tr1Y2LxeWdnW+4n0HXe3bnS4sza3Drm0i+d91JxrX8pBB1403DGHTf4N+wxXyE/eFFUiZU4arwQIwOt8+Nn2Za7YvhMDdkxbj5N+/HXgNuXiT8zUu37QTz85aaetZ5TWr//ZD79lk6N+tBqu3ulNot+7M1onEQ1oSTjIC6NfVP3ZC8I6BxJ0WiOXCItz37SNyistI1KwyXx+9VzPFgBhILi4/P5zvv1OB6V6Ddx2IM8HC+C+VlNdPyK8liR8xIpywb19cPn4f7b4o16l0WIEUmPXNrZi7cmve15HfrULKw3BTAAAgAElEQVS4Dp58bzneWbxBu2/d9lY0XvcSZpgNDsMyd+VW3PTCxy4FsnjdDtw9KVxxXjItMH/1Nry/bLNr3/zV2zFjaXa71+yzNZmxBc37d6vVxo22t2YVSIzIZQ2EIZ3JoEd9le8xAt4xEGdlunxNuYwjzm9Ft1p/uZz3DNtMUQbrrxi/j7YQMywj+tvjMs54kPPz0BXredVVODfL98Z59HOXHW2/R47jNxHwt4uOxE9P2883BhIEKxDGxWl3T8WEe6flfR351SqEBXLDv+bj/Iff1+6bvXwLAOCRactyuraaMvvWovWuausgzvrTuzndV+VPbzYBMNJkB3SvxcrNbgWitiwJm03lJJURoVyLXtZN0tE1MuYIaOexFIrDAvGWUd7T1UxR87ERAd87cTgAYGDPOnxZs4hVWOqr7QmfQS4snd/Ja3AOXpHQ+D+6sZfnedHqQNRre8dAAq8T/pZlS8UpECI6jYgWEVETEV1XanmcbNb433OC/M3vQiEHfGcgOixq/OHCv82MVNEbBVl0qGPBGiM4PvOGk9G/Wy1aPJopSnTZVH4zx1pznQbVgvA7XlVO4/ftaz1OOV6D0xrwWno1DKoFYhvDHJfMWj1hXFiErx4xCMvuOBP11Ym8fPYNNfYYjSuhwOnC0lwjbCuT/QIab2avl33s970d2KPOIZsaO/GXxY9OYIBUlgIhojiAewGcDmAkgPOIaGRppapsZFA4qCutF3dPWmx7XgiLQkeYpocNNXHXTFcHkTsG4pdy+bUjBgHIZo19fMupmPPzU7yvrzw+78ghOMlc68G53rpcQEgOjPmsxtg9wLUmkcrN6Y0KysIynvtYNgGDYaAFEiKN1+szUmX/4Oen4MCB3c2L+MsU1lp44apjcNiQHtnzlPfOvV66+5pPXTIGT108xrW9UhJl/KgoBQLgSABNQoilQoh2AM8AmFBimYpCIV1YfshBTF0XIwh1Ju7MvtoZMPvPFbmK4NDe+vTb+uo4EvFY6FXdwhTSSarjhpKVA3xDTQJdQ8YcEjGyZrdJh5KuNZU3FUCB9G7IBuBt8QOPWEegCwnu98Tf6vJ/37vU2BWIV0aaH2HG254N1ZqtHs0Uba4o72v26VKDI4Zk26jYLBDNeU7rauw+fTB2WB/vG1QwlaZABgJYqTxfZW6zIKJLiWgWEc3asEEfOK4Esl/u4moQGcxUXVivf7wWE/78rmeb9VQ+zvockRaI1yxUDlBhYzBhXDgSmfKrvm4/i0V9d2IxsmIbznvI1Ft5qShvqzpw/egLI3D6geHSgL0WsSJtGq/9ud8AXhVggjgD8EExKN1er0SK6ngMRwztaSseBLLW9fB+epdWFAtAPdReH+PmrR+f4ArYd1Y6XSsTIcREABMBYNSoUWWaBBuMnOUU2wKRJnibYoFc/cwHaE1m0JpKa11CxYpz+CEVnNcyqVkFEq4ewolfWm+1OdiFXbtdfXvilLVALhjbiD171OH5OasAZGMr2SB6bu/rlScMsw2GfuOi94qEOheWPj3W77peuNYfCbh/lDTeWIzw/OVjXdu711XhqYvH4ADp0vIhKNvRq/pc954M7FHnipt0VirNAlkNYLDyfJC5rdPRUe5ROSaqMZCgcawUFoiMH6gz1x+cPMJ6LAewqFlgEr/W29JKy+V1x2Nkuaa61CRw0xezIbsahwWSqwvLZU34yeORxhvGhSXFO1GzfnfQ6oMuiy9gPRJdGq96TEPI3l9jh/VB97pgd2OuX+liV+iXO5WmQGYCGE5EexFRNYBzAbxYYpmKihzMhRDYujN6hlfQrFlngUjUAW3hmu1WdXk+vvoonH/0UOvxJjO7TfW1X3hMI3454QAA2dl7LhXmgL9/X65kGPZ1q0cdPqSnJVssZr+PMwZSKMtOHWgH97TPhK1eWCEWlHK+J/K7NGavXq5jvSwQmREV1P03jAWiKqGPfnGq9n65EiUDTlUa5Vro21FUlAIRQqQAXAXgNQALATwrhPi4tFIVByuIbn5ZH3r3Mxz6yze0NQ5++KW/AtmZlxoDkb8J9dTT75lqVZd3lAL55pghrm2qrz1GwCBzgNxuphPnaoH4LRQ1dp/eAIBvjBrseYyKHIwuHNuIuuq4LQaiDpR11U4XVmSxfTnz4AEY5vD/e9WBhFkBUFpgOmvDywX47yuPwbxffCGw95Z89r0Th9mee5HLErt+XHjMXtbjRIxcqcCVny9VHCpKgQCAEOJlIcQIIcQ+QojbSi1PsbAq0c1BZfJCo9tsVAXiTB11Ime9tjRZ85S0x/QqHwUyaqh+USAnH950ijbTSXVhxYgwor/xQ9/QbPS6qvHoCfWvK9w+chU/D8zgnvVYdseZONpUJGGRn6GcuTsViLRA/FxYhwzuoZXdtweTOdzt0c3dfiThYYGEyYJKmzMKXasWryys2qo4utVWBV6fCFh2x5nZNT86eMT+9lFZa3fJbafjlWvGhTpPTe/dHak4BbK7YAXR5XOpUCJeR6dAdrSl8J1HZmLFpp2WAmlVFIi0erwURaEskKtPHIZ7zj0Ue3Z3D3Q96qu1fnk1/TNGZAUrvzCyPwBvC+SwIf6Ky2+Ay3e2e83Jw1GTiGG/AV1trhmZheU3tn7x4AGBskdBvk5XLyqdC8vVQt/4r1MWgVlVrowup8vKaZHorydrcnJlYI+6wEJDInJnaHm8vAmHDsT060/MS6ZKptNlYXUEp/7hHezTrwF/+dYRxbuJRwql6icXQuCdJRtx3PA+nimJOhfWS/M+x+RP1qNHfTW+eriRBa0qBXkLL5+8l2USBlXMH5qzzUMH98Dxd77lOlbnVlEHKiLjxz7n56dYlc46BRJm/PdTILmuxicHwXHD+2LRracDsFt6MgtLV8PZtTaB5tZUTsVmTutVRY79TgWiX3/D/jxrgYR3YWWvFT7Qb8ij337X1w/BXV8/JOBsb6Zdl9tg71f7MaD77pFxpYMtkBxYtK4ZL3+0tkPuJb+surTef8xehQsefh/PzVrleb6zeA0ANu4wAtJ9ulT7+t09LRCHVZNLZ1sVr9mm7rpOCwQAejVUW+m7ujRer1bn0moB9L2gJEFLkw7upR9AdKepykjK1Z62F1/efc6hVl2H11vb6FFQqaLLEJLvtV/MR+KKgaRlDMT/c9FfyyFHwFcm12SIUvHPK8bilrMPKLUYHU5lfUq7Ec4gus6FtWqLscTn6q36pT4BuwurNZnGjKWbcOdriwAYA+9Hq7d5nuupQPJoIKfD63Sd60gdvHSWgVqJ/i0zCO/l1pp4/qisDD5z4qCXt7PNrgCkW62xT4PrWFVkmV66pSVpO+bofXpbs3zdrW//ykG45qThPvK6JxtOdC6nsw4egIcuUN4TZxaW8A6ie7Wwl4RZwErlsME98NPT9sMjF43G2z8e73tsvqjxj1w5fEhPXDC2Madzwyx+Va6wCytPtu5sR1U8hgZHqwYhwnVu9YIUjZFKZyxFYHNhWcd6X0e1QK555gOr+y5gdNL9o9nJ1ia7+V+nQNZua8UJd73lkNX7/mHwijFoLZC4aoG4z1Erni8Y24gn31sRerElL4JcWM72LacduAeeumQMjt7bHXRXvxNfPGRPvL14A84Zbc/uSsTIGqR1Onz8vn19W4f4SSsnJLrX9GezkrtbbcLIanPcW2Zh6T6XQDefRxrvRcc04oYz9ncfTqRdb6PQLLvjzFDHhW17Uqz7lytsgeTJob98Q+u/L1RKpoCxeNN0uV6HrQrWtE58hgy1+O3NT9ZjlzLYbd2V1J1iXVcX65i13L12R1QL5IA9u9mee52tjYEo23QKuk+XGtQkYrjzawdbcuWa2mvJEfD6blaKA4Uw5Bq7j3dcSlJbFcefv3k4xg3va9telYhZM3pnB18g+36/cOUxuPucQ0O9BlU+wN/t+OJVx+K7x+2Nvo7Fs9J+abwBhYTuOg/jOYECzy0HOI1XD1sgBWDjjjbXNmMQzv1rpxY2ffz59ux2TRFTWAskHiNrFUBAv3a4cQ8DXRFiL02zuqgWyLPfPdq1wJOOIAWio646bgWsF5jvm4yLNPaux7JN0dKggeAsrHOPHIKhvRtw3gMzIl9bR1UsZg2qzjVEgOy36pDBPXDIYHcaaZjPw89iaOzTgOs1VoGvAgkMokeXsVzpVsfDpoTfiQLx4cqt+JKykFS+Bohaga7bbtxD1hd4X0eNgRh9mbL71JX8dKSFwPJNLRjaO+vL16UFR1tEh9BQk7C5/LxO16bxRpitykWWZP3GpB8e7/m55NuSQn4GYd+KAwd289yXiGddWLo29mFdo7rqarkll8QHy4UVoQ5EEjUGUm70rDcmTl89fBAG9QxOYNhdCK1AiOhYAMOFEH8jor4AugghPiueaOVPSpndv/jh57Z9GSHw4NSleOmjNfjXFcdEvraMdXyyttm2XdfIzW9AUV0gzpm0pwViXveeSUvwyvy1ePPa47XXs66b51igin/1ScOtGXZQED2Iwb3q8er3x2GfvsZyqrpB7sYz98d/5n6OzTm0iVGRsobxj7/xg+PQX1P7IknEyGrgqMuiC8LvHcq2VYn+oUkLJBfLMEq/rnLkwmMaUVsdxzePdHdH2J0JNZ0jopsB/BTA9eamKgBPFEuoSkFd+c45hj849TPc+tJCfLAit/XRpaXgUiAej71QXSDOH3mzwwJ527Fu+ivzjVRl1e2ls0DyXRhHjeH88JQR+MEpIzyPjbqW+X57dPNt9HfxuL3xwlXHWjKcoqT2RiHKOzC8f1ffNcyJKK8GjlYWlm6nuTEorqMjHwXibPcub18phkhVPIZvHzU055qgzkrYX+OXAZwNoAUAhBCfAwi3bmQnZpfP4kmP/G9ZXtf2KuKzFxIa//1+hDYXlkuB2IPoFzz8PlqT7tekuht0A1q+v6ko50exQKIgXVjnhOx35cQKChdIvITDhTXlR+NDnyvrUvbWpBFL8rJANC8yqBtvl1q7syNMqjFT/oRVIO3CcKgKACAi72/mboTqXshl3Hj0f8vwnsyucuDVHVQXA/HLwnIG0VW2a2IguqVtX1DcczqXSr6zsij+8GLPAHO9vlTsJ2lanYdFbTvudGHt1acBfbroVttzc+J+/fGPy47W1iXIr08uMYiUjwUS9L45VyTkeXznIGwM5Fkiuh9ADyK6BMD/AXigeGKVlubWJJ6YsQLjhvfJrq+swaZAHL+IMDOrm180GgnrcsG9PRduC+Q3r36Cvfs24NQD3KvStSlBWKf7x2mBAEBSE7S97+1Prcf65ozFKSTUUayUT6mEo8zMu9QkrDjSYYN74OYvjgzdsVfHq98fhxVmlliVlYWV21r1oxrdLdeB7MQkl7dRtjLRB9H937euLgvE/p+pTEIpECHEXUR0CoDtAPYFcJMQ4o2iSlZC0hmB37z6CaoTI30ViOrOccYB2hRXUCYjIrsMvF1Y2ceqlfLdx2drFZHapt15TV2K6IPv+udFtGkUTKSXpjk2SgwlaOnUXJHWXJTspKk/OcGKIyXiMVyktATPhQHd66y+SlU+abz54LW8bhhUF1Z1PGazVoOKNZ2dlf2sZqZyCJyHEFGciKYIId4QQvxYCPGjzqw8AKBbbRXiMcLmFnd9h4qaYun8OTQrGU66uIHTRXXvlCY0XveS9SP1skB0MRDJEzOWAwC27Uzi2mfnYkdbyjbgb24JzjT661uf+u7XxUics8uolIMFIokiS8+GagwJ0ZMqF+QiVqoF4lxXPArHjTCKFeX3J5fEBzWIrraMAYw2KH6V404XVsRcCKZMCfwYhRBpABkiCl5YuJMQixF61ldhc4u+UlsSNkNGl/qqDuzX//Mjqz+VHDC8YiC2rrmOfTf+ez4A4M9TluD5OavwzPsrbPfRWQ9R2eVQICfv3w+XHZ9fywm/2fANZ+yP0Y3Zdub5Nm7MR5aORFpaqgJ5/OIxuPqk4aFjISoTv30Epl13YjaNN4eXmW1lEsN3jjWsLanUquIx/PS0/TzPdQbRy+V9ZvIj7DxgB4CPiOghIvqj/CumYKWmV0N1oAVi80/7ZUJlBDbtaMPiddmUXHUm//T7K6zH8gfu2Upd03bdLZccJMjmSisETgvkyhOGoS7k+tRe+A0llxy3N44Z1sd6HuRrz5dyGdiG9zdqV9TXvk/fLvjhKSNysh5qq+IY2KPOWmUylzTeS8btDQDo07Ua15w0HEt/fQa61xuuqSCFlK+VypQnYT/Vf5p/uw29GqqtLqnLNrbg1LvfwSvXjMPeZlEa4MzC8inmSwuc//D7+Pjz7fj012e4WorYjg1wYdktEPdBT8xYbh2TiBOaWwurQJypy/EY5T3oBq5Wp7y35eTCKibD+nXFrBtPRm9N65h8yMeFdcHYRltmF5HaZ8z/ejVx+yRDdiwuk7ebyZFQv0YhxKMAngYw2/x7ytzWaenbtRYrNu/E+59txvi73kJbKoMX59qrzdUAp28tRiaDpRtaAGT7M3nVkKQ1XXdV/GIggOHGSousrzqs2+rWLx0Y6jhn63hDgYQ61ZOgsUy9frGC6Lp7lZo+XWryLtJ0ko8LS4cMngddL65YjlN/coLVHYCpbMJWoo8HsATAvQD+AmAxER1XRLlKzsn798Pa7a34xv3TrW3OTJNUyBTLVFpg/wFG3WXTBsONJS0Q5/ggB38v95RX3KVWCWpKJZSIEdpSaSRihKEBwd6wHWtldbpEZ4HolqiV6MaZoDFS3V/sOpBCD9jlRj5ZWDrk9y7ofVNdZoN7cS+pzkJYf8DvAHxBCHG8EOI4AKcC+EPxxCo9sgGfSk0ihv99utF6rrqwghoadjHTGLftNNxispGhc+C2srA8FEXGFgPJPm6oznojpZIxYiAZ1FfHLZeBF7muAJfQKBC/wUT3qgJdWMr+oIrnfCmXGEixyCjWaSGoNTsdB9WrOO+Xb/NKpjwIGwOpEkIskk+EEIuJyLuZTyegX9da9OlSbS3/CgCrt+zCLf9ZYD23ubB81+TIoIu5Zve2XSk0rW/GORON1t/V8Rhakxnl2CgxkCz1NXFsapHHGNeLkeHCqqmKW7GDuqq4Nv6iWwrWj3iMkM4IxIhcKZlRx+Cgw9XrFTuI3rnVR/Z7VSg9KdN5ZXLFb796sJUAoOKlsDq5vu70hFUgs4joQWQbKH4LwKziiFQ+DOheZ1MgrSn7wOtXia6SyghLwWzblcT81dn1PaoTcQDZmpFMxj8GorqwMh4WiNRrqUwGbak0ahIxK/21tiqmVyBV0Wb2QpnJOi0Ov9mtbk/QrF/dv7uk8RaLjGKdFgJpgbSZk6BvjNZX4nt9bNwLq7IJq0AuB3AlgKvN51NhxEI6Nc7ZrvPLrm/r4SaVFlYtyLZdSZv57hwQpYLwqgPxCqLXK6m00gJpTwu0pTKoTsSsQd2wNNz1LTURXUPy1vEYuVJCow5OUYLoxR7gO7n+KLwLy4wLOidXTjp7bGl3JawCSQC4Rwjxe8CoTgdQ439K5eMc3J1rfrSHbKaYymQs19M2j2VkJXLw93ZhZR/bXFiKBfLyR0agO5nKoC2ZQU0ibnWx9bI0olsgxn9dED2yCytCGi8rkPyQ38NCvc6zD90TL320BvsP8F4gy4/O/n53dsKOGpMBqFHYOgCTCi9OeeFqPuhYgEnNwvrjm02e10mmhfXD3b4rqe2oK5GX9C4kzN5TPUSXRZXKZNCaTKO2Koa4+Vqky6E6EbP1zqqO51YMGCd3Gm+hB3n1csUecDq7C0tSqNd56gF74LPbz4iclsuuq85BWAVSK4TYIZ+Yjzt9Ll5QwDZsK5N0RljHOi0Ql1ssggWi2iC67KRkWqC5LYWutVWWNeVlaeSahRWPkatRZKGHYNVCKfYA39kVyF1fPwTfHDMEo4b2DD44JPm4p9i1VdmEHTVaiOhw+YSIRgHY5XN8p0AOJpeM03dZ1a2doSOVzlgWxdZd9oaGTkWRDoiBpD1iIKqy62m2l0imM2huTaJrTSKrQDwURdg6ECc6F1ahB2GbfiryeNPZx7PBverx6y8fVPSK/rB4fc+ZyiDst+j7AJ4joqlENBXAMwCuKp5Y5YH8atd5tKoOHUTPCOvYbQ4XljN//sZ/z8eWlvZQLiz1GLVT6+1fORjxGCGZzmBHawpdaxOWgpHpus5xMkp67PdOHGY9jmkq0f0G4VwGaPWU4lsgRb08w3QqfBUIEY0moj2EEDMB7Afg7zBSeF4F4L9wRCei1qNZ4O/fWBzqfDWI3prM2CwXZzX7vFXb8PiM5YEuLCEEnp21ytquKoCT9++HqjghlRZobk2hS01CycLycGFFmJGedfCe2ftq0ngLboEoo3qxxvfs8sDZO7z/s5Mw4/qTinTH3ZsGs727c50QprIIGjXuByB9LkcD+BmMdiZbAEwsolxlhZcFEpZkWthcT2ocRLdg0B7dagN7Ya3cbPcgyhjID04egUQ8hqqYUe+xK5lGl9qEtd8rBtK9vgr3f/sI27YrPNZ3UOMlMSJXSmihjYSO9JOrd+rXrRZ7+LRlYXLn3NGDccMZ++O7x+9dalGYPAhK440LITabj88BMFEI8TyA54now+KKVnqkfzZff3E6I2wV5KoC0cVRaqpiPq3ajeOdY6pUEHJ7VSKGrWbblK61VVbzRi9LI0ZkWxL3k1+dhmQ6g79oFpiqUqydeMxdg1/oflXq1YrtMe/sQfRyIRGP4ZLjWHlUOkEjY5yIpJI5CcCbyr7dpsF/vh1gk+mMLV6iW9XPfrzwrkQ3r+PMAJODupQ0ESOs3dYKAOhak7CsBln4deZBA2znOwfO6njMpghU60S1QHTrShTaYujIQZ0VCMOEJ0gJPA3gbSLaCCPraioAENEwANuKLFvZUAgLJCMEEjFCKiMCc+CTStaWbt/0Tzdh3fZW23aXBRKP4f1lmxEjYMzevbD2w1bztRBm3nAyetQ716i2E3NkV6nWSXU8hr5da7ChuU271nuhA9HqmF7srB3WHwwTHl8FIoS4jYgmAxgA4HWR/fXGAHyv2MKVGvlqq/Js4Ge0MhFIxA0F4qUcJE/MWI6PP9+u3deezuC8B2a4tsvBXs7+pcz9u9ViaO8Gy2rICKBvV3cTAd3A6dV3qjoRw7+uGIt5q7Zpz/V7t/yaTnrRkZlRnFXKMOEJsyb6DCHEv4QQLcq2xUKIObnelIjuJKJPiGgeEf2LiHoo+64noiYiWkREpyrbTzO3NRHRdbneOxecFelRSZpZWNJKSAcUIHopDyDbBt7JcSP6AgDGmm3opatKLiUq7+01g9e5nbxiGVXxGAb1rMcZDjeYxM8NlG8bbx7fGaZ8KFU10RsADhRCHAxgMYDrAYCIRgI4F8ABAE4D8Bciipu9t+4FcDqAkQDOM48tKnKwy9cCkUF0GcAOWcCuxUu5HLlXLyy740wcNsSoMK6xFIjhqpIWSJDyUnEqlRvP3B+A2zJx6qSixhGKrEGIgB+fui8mOjLSGIZxU5JAuBDideXpDABfMx9PAPCMEKINwGdE1ATgSHNfkxBiKQAQ0TPmsQtQRLIurDwtELMXlqzV8FosKgzOJWW9qDPTdaUFUi3vnccAfPG4vXHxuODMGd9CwhxcWOo5xV6ISAjgyhOGBR/IMEzJLBCV/wPwivl4IICVyr5V5jav7R1CvosYpdJ2F1ZQDKQQ1DosEGkVFOPeToXBmUwMs3tQNAuEiCYB2EOz6wYhxAvmMTfAWE3pyQLe91IAlwLAkCFD8rqWHGvzHRBTZjNFuWZHOs9BvGd9Fbbs9G8LX+eIgch4Rj7WT1iK6sHqABcWwzDhKJoCEUKc7LefiC4EcBaAk5TsrtUA1CXNBpnb4LPded+JMKvkR40aVZDhhgAM69cFTet3BB6rI5UWSGcyliWT7yDYu0tNoAJxBtGzFkh+9w5DoQsJnW6re849NOfmj4H34ig9w4SmJC4sIjoNwE8AnC2E2KnsehHAuURUQ0R7ARgO4H0AMwEMJ6K9iKgaRqD9xWLLqQ5ck354fM7XSWcK68Lq1VAdeIzUyT3rjWPlzLoj3GfFbD0iBDDh0IE47UB9BhjDMB1HqarJ/wxjRcM3zMFmhhDiMiHEx0T0LIzgeArAlUKINAAQ0VUAXgMQB/CwEOLjYgtpjbV5jodJMwuryicLa9zwPpi6ZKNtW58u1bY12dXtQew0W5dIZSMtkCD98fzlY111F2ccpPNEZnEGxivRC9SnSw1WbdmVd7yLYXYnSpWF5ZnmIoS4DcBtmu0vA3i5mHJ5kUvmkEoqnUEqI6x0YJ0V8NPT9sPUJe/athnL1LoVSPe64A6mu8x2Kb1NBSLdSkFpvEc4Fhr67PYzAu+1V98Gq8o+iHyNk2LZTxPPPwJTPlmPPXvUBR/MMAyA8sjCKlsKNVjJ6nPLAtEMtL01VkW9Rxt5df1zL1rM5XezWVjG9qguLCJ3u3YnXWoSaPr1GRiZ47rYAPDIRaPx+g+O08ugpvEWyQXXr2stzhmdX9IFw+xusALxYVg/Y51nZ9+oqGRbmXjHQHo1VGPBL0+1bZNrJjhp8FAsKruSRtdeqYSoA4Poudxi/L79MKJ/V4/rKasw5igTwzCFhxWIDzedNRKPf+dI7J/HzBowGiAK4V3MR2Q0KHRaFgfuqb9vvUOx6FxaPztjPwzuVWcpwUE9DdfMoYO75/QawsApsAyze7HbtGTPhdqqOMYN75v3ddpShjUge2o5XVhCuDOXnrpkDEYN7YVHpy93XU+1QF79/jgM7lnvOmbc8L6Y+pMTrecH7Nkdr33/OAw3FUoxYAXCMLsXbIF0ANZiTonwabw1iRiqEzF0q3XreNVS6dVQ7enqcrLvHl1d7dePH5G/gpTIWEUxW6736eLuJMxUBl0132WmsuFPtAOQGVFSgbQm3asQOrG652r2qcH1fDsF/+3C0XlXxkchHytlaO96V5YYUzm8+9MTrckU0zlgBYADNUAAABCMSURBVNIByBUIZfX09KWbbPtP2DdrBfTvVoN129tc7VPOGTUYiThh3qpttgWu8q1biMUIsQ6s3MhHV43Zq1fhBGE6nO51VaFS0JnKgV1YHUCrwwJx8t3j97EeXzHeKJHp6ag2P37fvrjtywfhP987FmpzYK9Fn0pBsWMg3GaEYcoLtkA6AOmy8lIgXZQYxgVjG/Hlwweim1m/IX1Yqp5QrZNC953KBymJ30DPgXaG6TywBVJkRg7oZsVAajzWFeniCIJbysOGXmnkGwNhGIbJFR59ikxDTdwVRHdSXxNcGKjO3ONlaoF8a8xQAMDgXu60YoZhOh+sQCJw8KDoRXiJWMw3BjJ2n97o3eCdmqrr51jMbrf58I3Rg7HsjjPRq6E4gdIyfdkMs9vCCiQCT148JvI5ddVxNLcafamqNS6spy45KpQVUa5xDx35Np9kGKYyYAUSga61VVZ327D0VQrfqhPBriovbC4s/tQYhikDeCiKiBzIbzxz/1DH9+2aVSD5rKJHHllYlUY+1gmn8TJMecEKJDLGALhPyJ5S/bqpFkj0t1u2BaEKcmExDLN7wAokItKKCGsF9OuanwKRqHerFAvkh6eMwORrc18K2EmFvGyG2W1gBRIRuURs2LHswIHZzK28FIgyelaKAgHcsu7RvbZEkjAMU2i4Ej0iUoEk08ENEQFgkNJq3auQ0A/p9o/ZguiVpECyj/9wziE49QD/9dUZhqkc2AKJiFQgm1uya5VffaLnEu828nNhqTGQnC/TIcgGj/EY2SyQLx06MNRyvAzDVAb8a46IVCBbdmYVyEiPlQOd5OfCyj4udxfWJeP2xpaWdlx0TKNN0ZZrASTDMLlR5nPZ8uPy8fvglJH98Y1Rg5Wt4QbG3LKwzDtUkAJpqEnglgkHor46URClIV9vnPt+MUxZwRZIRPp0qcED54+ybQsbkqjJp5DQo5liuVMIUSccOhAL1zTjmpOG538xhmEKBiuQAhA0y65JxNCWyhSukLCiFEj+slYnYrjpiyMLIA3DMIWEfQIFIGg8l+t45zOWqqfGy9yFpVJBojIMExG2QApA0CD5+HeOxL8//NxSJFEQZiKvanVUUiig3OM1DMPkTgUNReWLGp84+5A9Xfv37tsFPzxlRF6WQ6VaIKxAGKbzwgqkAKhj5DmjB4c6Lp97VNKgXEHhGoZhIsIKpACoQfR0xrtlbC4prdk0XtWFVTmjMq8NwjCdF1YgBUAdz4vVcdzmwqokBcLfMIbptPDPuwCos+yx+/TGeUd6u7Fyvofazr2iXFiVIyvDMNFgBVIAVIOgKh7D7V85uGDX1jVTrKwsrFJLwDBMsaigoaiM6YBBUrVyKmlWX0myMgwTDVYgBaAjBknbmugVNChXkKgMw0SEFUgBKOoYqYnKcxYWwzDlACuQAtARbcor1RVUQbqOYZiIlFSBENG1RCSIqI/5nIjoj0TURETziOhw5dgLiGiJ+XdB6aR2UxXvWBdWJVGpio9hmGBK1guLiAYD+AKAFcrm0wEMN//GAPgrgDFE1AvAzQBGwXDqzCaiF4UQWzpWaj1VHbBEoG4cHlAB64uz/mCYzkspmyn+AcBPALygbJsA4DEhhAAwg4h6ENEAAOMBvCGE2AwARPQGgNMAPN2xIuvJp017EFYzRcdI/NxlR2No73rdKWUFr0LIMJ2XkigQIpoAYLUQYq5jgBkIYKXyfJW5zWu77tqXArgUAIYMGVJAqb3JZ6nasDiH4dGNvYp+T4ZhGD+KpkCIaBKAPTS7bgDwMxjuq4IjhJgIYCIAjBo1qlidRWyUyoXFMAxTSoqmQIQQJ+u2E9FBAPYCIK2PQQDmENGRAFYDUPuADDK3rYbhxlK3v1VwoXOkmBaIrpkiwzBMOdDhWVhCiI+EEP2EEI1CiEYY7qjDhRBrAbwI4HwzG+soANuEEGsAvAbgC0TUk4h6wrBeXuto2b2IYoE09q7HRcc0Rr4Hqw+GYcqNcluR8GUAZwBoArATwEUAIITYTES/AjDTPO6XMqBeDngF0ffUZEm99eMTAAB/m7Ys0j3YAmEYptwouQIxrRD5WAC40uO4hwE83EFiRUJngcz5+SkFyc7SNVNkGIYpB0quQDoDuvU5ejVUF/Qe3BKEYZhyg1uZVAjswWIYptxgC6REvHnt8aUWgWEYJi9YgZSIvft2iXR8JXXgZRhm94BdWBUCqw+GYcoNViAVAsdAGIYpN1iBlDlC6JspMgzDlBpWIHnQp0tNh92L1QfDMOUGB9Hz4N2fnoB0pkP6NbIGYRim7GAFkge1VfGi3yNbic4ahGGY8oJdWBUCqw+GYcoNViAVAjdTZBim3GAFUiGw+mAYptxgBVLmyAWlOAbCMEy5wQqkUqhw/TGoZ12pRWAYpsBwFlaFUMkGyPxbTkWCe3kxTKeDFUiFUMkurC41/DVjmM4Iu7AqhMpVHwzDdFZYgVQIFWyAMAzTSWEFUiFUsguLYZjOCSsQhmEYJidYgVQIbIAwDFNusAKpENiFxTBMucEKpEJg9cEwTLnBCqRC4GaKDMOUG6xAKgRWHwzDlBusQCoENkAYhik3WIGUOWP26gWAXVgMw5Qf3KSozHn4wtFYs21XqcVgGIZxwRZImdNQk8Cwfl1LLQbDMIwLtkAKxCMXjUZLW7rUYjAMw3QYrEAKxPh9+5VaBIZhmA6FXVgMwzBMTrACYRiGYXKCFQjDMAyTEyVTIET0PSL6hIg+JqLfKtuvJ6ImIlpERKcq208ztzUR0XWlkZphGIaRlCSITkQnAJgA4BAhRBsR9TO3jwRwLoADAOwJYBIRjTBPuxfAKQBWAZhJRC8KIRZ0vPQMwzAMULosrMsB3CGEaAMAIcR6c/sEAM+Y2z8joiYAR5r7moQQSwGAiJ4xj2UFwjAMUyJK5cIaAWAcEb1HRG8T0Whz+0AAK5XjVpnbvLYzDMMwJaJoFggRTQKwh2bXDeZ9ewE4CsBoAM8S0d4Fuu+lAC4FgCFDhhTikgzDMIyGoikQIcTJXvuI6HIA/xRCCADvE1EGQB8AqwEMVg4dZG6Dz3bnfScCmGjeZwMRLc/5RRgybczj/I6iUuQEWNZiUClyAixrMSiGnEPDHFSqGMi/AZwAYIoZJK+G8Qa8COApIvo9jCD6cADvw1gOYzgR7QVDcZwL4JtBNxFC9M1HSCKaJYQYlc81OoJKkRNgWYtBpcgJsKzFoJRylkqBPAzgYSKaD6AdwAWmNfIxET0LIzieAnClECINAER0FYDXAMQBPCyE+Lg0ojMMwzBAiRSIEKIdwP/z2HcbgNs0218G8HKRRWMYhmFCwpXo/kwstQAhqRQ5AZa1GFSKnADLWgxKJicZniOGYRiGiQZbIAzDMExOsALRUG59t4joYSJabyYdyG29iOgNIlpi/u9pbici+qMp+zwiOrwD5RxMRFOIaIHZ4+yaMpa1lojeJ6K5pqy3mNv3Mgtcm4jo70RUbW6vMZ83mfsbO0pW8/5xIvqAiP5b5nIuI6KPiOhDIpplbiu7z9+8fw8i+gcZPfkWEtHR5SgrEe1rvp/ybzsRfb8sZBVC8J/yByPL61MAe8NIL54LYGSJZToOwOEA5ivbfgvgOvPxdQB+Yz4+A8ArMFKfjwLwXgfKOQDA4ebjrgAWAxhZprISgC7m4yoA75kyPAvgXHP7fQAuNx9fAeA+8/G5AP7ewd+BHwJ4CsB/zeflKucyAH0c28ru8zfv/yiAi83H1QB6lKusisxxAGth1GmUXNYOfwPK/Q/A0QBeU55fD+D6MpCr0aFAFgEYYD4eAGCR+fh+AOfpjiuBzC/AaIBZ1rICqAcwB8AYGPVICed3AUYK+dHm44R5HHWQfIMATAZwIoD/mgND2clp3lOnQMru8wfQHcBnzvemHGV1yPcFANPKRVZ2YbmplL5b/YUQa8zHawH0Nx+Xhfym6+QwGDP7spTVdAt9CGA9gDdgWJ5bhRApjTyWrOb+bQB6d5CodwP4CYCM+bx3mcoJAALA60Q0m4y2QkB5fv57AdgA4G+ma/BBImooU1lVzgXwtPm45LKyAukECGOaUTbpdETUBcDzAL4vhNiu7isnWYUQaSHEoTBm+EcC2K/EIrkgorMArBdCzC61LCE5VghxOIDTAVxJRMepO8vo80/AcAv/VQhxGIAWGG4gizKSFQBgxrnOBvCcc1+pZGUF4savH1c5sY6IBgCA+V+2xC+p/ERUBUN5PCmE+Gc5yyoRQmwFMAWGK6gHEckCW1UeS1Zzf3cAmzpAvGMAnE1EywA8A8ONdU8ZygkAEEKsNv+vB/AvGIq5HD//VQBWCSHeM5//A4ZCKUdZJacDmCOEWGc+L7msrEDczITZd8vU+OfC6NFVbrwI4ALz8QUw4g1y+/lmJsZRALYpZm5RISIC8BCAhUKI35e5rH2JqIf5uA5GrGYhDEXyNQ9Z5Wv4GoA3zVlfURFCXC+EGCSEaITxXXxTCPGtcpMTAIiogYi6yscw/PXzUYafvxBiLYCVRLSvuekkGC2Uyk5WhfOQdV9JmUora0cHgSrhD0YWw2IYPvEbykCepwGsAZCEMXP6Dgy/9mQASwBMAtDLPJZgrN74KYCPAIzqQDmPhWFGzwPwofl3RpnKejCAD0xZ5wO4ydy+N4wGnk0wXAU15vZa83mTuX/vEnwPxiObhVV2cpoyzTX/Ppa/nXL8/M37Hwpglvkd+DeAnmUsawMMS7K7sq3ksnIlOsMwDJMT7MJiGIZhcoIVCMMwDJMTrEAYhmGYnGAFwjAMw+QEKxCGYRgmJ1iBMIwHRJR2dEH17cxMRJcR0fkFuO8yIuqTw3mnEtEtZpfWV/KVg2GCKNWa6AxTCewSRquTUAgh7iumMCEYB6PAcByAd0ssC7MbwBYIw0TEtBB+S8a6F+8T0TBz+y+I6Efm46vJWBdlHhE9Y27rRUT/NrfNIKKDze29ieh1MtYleRBGIZi81/8z7/EhEd1PRHGNPOeYTSGvhtF48QEAFxFROXZQYDoRrEAYxps6hwvrHGXfNiHEQQD+DGPQdnIdgMOEEAcDuMzcdguAD8xtPwPwmLn9ZgDvCiEOgNE/aggAENH+AM4BcIxpCaUBfMt5IyHE32F0Pp5vyvSRee+z83nxDBMEu7AYxhs/F9bTyv8/aPbPA/AkEf0bRpsMwGj18lUAEEK8aVoe3WAsGPYVc/tLRLTFPP4kAEcAmGm0GUMdsg3znIwAsNR83CCEaA7x+hgmL1iBMExuCI/HkjNhKIYvAriBiA7K4R4E4FEhxPW+BxlLx/YBkCCiBQAGmC6t7wkhpuZwX4YJBbuwGCY3zlH+T1d3EFEMwGAhxBQAP4XRUr0LgKkwXVBENB7ARmGsl/IOgG+a20+H0dQPMBrlfY2I+pn7ehHRUKcgQohRAF4CMAHGMqc3CCEOZeXBFBu2QBjGmzpzJi95VQghU3l7EtE8AG0w2myrxAE8QUTdYVgRfxRCbCWiXwB42DxvJ7KtuG8B8DQRfQzgfwBWAIAQYgER3Qhjhb8YjG7MVwJYrpH1cBhB9CsA/F6zn2EKDnfjZZiImIs7jRJCbCy1LAxTStiFxTAMw+QEWyAMwzBMTrAFwjAMw+QEKxCGYRgmJ1iBMAzDMDnBCoRhGIbJCVYgDMMwTE6wAmEYhmFy4v8D18ZSpj3B3K8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Agent(state_size=8, action_size=4, seed=0)\n",
    "# agent.qnetwork_local.load_state_dict(torch.load('checkpoint_Dueling_DDQN.pth', map_location=lambda storage, loc: storage))\n",
    "\n",
    "\n",
    "def train(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"\n",
    "    n_episodes (int): maximum number of training episodes\n",
    "    max_t (int): maximum number of timesteps per episode\n",
    "    eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "    eps_end (float): minimum value of epsilon\n",
    "    eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=300.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint_Dueling_DDQN.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = train()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-55e3a3fa170c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gym/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gym/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_polygon\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gym/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_buffer_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_color_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m# In https://github.com/openai/gym-http-api/issues/2, we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl_py35/lib/python3.5/site-packages/pyglet/image/__init__.py\u001b[0m in \u001b[0;36mget_image_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2153\u001b[0m         \u001b[0mglPixelStorei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGL_PACK_ALIGNMENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m         glReadPixels(x, y, self.width, self.height,\n\u001b[0;32m-> 2155\u001b[0;31m                      self.gl_format, GL_UNSIGNED_BYTE, buffer)\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0mglPopClientAttrib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl_py35/lib/python3.5/site-packages/pyglet/gl/lib.py\u001b[0m in \u001b[0;36merrcheck\u001b[0;34m(result, func, arguments)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0merrcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_debug_gl_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Agent(state_size=8, action_size=4, seed=0)\n",
    "# load the weights from file\n",
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint_Dueling_DDQN.pth', map_location=lambda storage, loc: storage))\n",
    "\n",
    "for i in range(10):\n",
    "    state = env.reset()\n",
    "    img = plt.imshow(env.render(mode='rgb_array'))\n",
    "    for j in range(200):\n",
    "        action = agent.act(state)\n",
    "        img.set_data(env.render(mode='rgb_array')) \n",
    "        plt.axis('off')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        plt.savefig('4video/' + 'file{}{}.png'.format(j, i))\n",
    "        if done:\n",
    "            break \n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make video prove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '4video'\n",
    "video_name = 'video.avi'\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video = cv2.VideoWriter(video_name, 0, 30, (width,height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [link]() for video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Традиционно, Ваш ноутбук должен быть воспроизводим. Не забудьте сохранить Output   \n",
    "Загружать ноутбук сюда: http://bit.ly/dafe_hw "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
