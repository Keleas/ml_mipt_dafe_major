{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-14T09:27:29.953979Z",
     "start_time": "2019-09-14T09:27:29.791801Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар - Генерация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка\n",
    "## 1.1. Выбор корпуса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня мы разберем принципы работы с рекурентными сетями с использованием фреймфорка Keras. \n",
    "\n",
    "Вашему Вниманию, представлено не сколько вариантов текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brodskiy.txt', 'potter.txt', 'pushkin.txt', 'potter_full.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = 'txt/'\n",
    "files = os.listdir(directory)\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите понравившийся текст: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'txt/pushkin.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = directory + files[2]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина корпуса: 66090\n"
     ]
    }
   ],
   "source": [
    "with io.open(corpus, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('Длина корпуса:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на часть текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "о сколько нам открытий чудных\n",
      "готовят  –  просвещенья дух\n",
      "и опыт, сын ошибок трудных,\n",
      "и гений, парад\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируйте последовательности длинны `maxlen` со сдвигом `step`, следующим образом: \n",
    "- В переменную `sentences` включите последовательность\n",
    "- `next_chars` список символов который является следующим для указанной последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 70\n",
    "step = 3\n",
    "sentences = [text[i: i + maxlen] for i in range(0, len(text) - maxlen, step)]\n",
    "next_chars = [text[i + maxlen] for i in range(0, len(text) - maxlen, step)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колличество послеовательностей: 22007\n"
     ]
    }
   ],
   "source": [
    "print('Колличество послеовательностей:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на случайную пару: Последовательность/ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После строки:\n",
      "яжко мне твое явленье,\n",
      "какое томное волненье\n",
      "в моей душе, в моей крови\n",
      "\n",
      "Ожидаем:  .\n"
     ]
    }
   ],
   "source": [
    "check_ran = np.random.randint(0,len(sentences))\n",
    "print('После строки:')\n",
    "print(sentences[check_ran])\n",
    "print('')\n",
    "print('Ожидаем: ',next_chars[check_ran])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Векторизация\n",
    "Далее, нам необходимо векторизвать каждую букву, для этого воспользуемся обычным Bag of chars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего символов: 61\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text))) #Составив список всех символов\n",
    "print('Всего символов:', len(chars))\n",
    "# Составьте два словаря\n",
    "# Первый: список букв:номера индексов\n",
    "# Второй: номера индексов:список букв\n",
    "\n",
    "# Ваш код здесь\n",
    "\n",
    "char_indices = {token: idx for idx, token in enumerate(np.unique(list(text)))}\n",
    "indices_char = {idx: token for idx, token in enumerate(np.unique(list(text)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составьте обучающую выборку, где:  \n",
    "- x - это закодированные последовательности, размерностью: (количество объектов, длинна последовательности, колличество уникальных букв), таким образом каждой букве в последовательности будет соответствовать вектор\n",
    "- y - это закодированные ответы, размерностью: (количество объектов, колличество уникальных букв)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация...\n",
      "... Готово\n"
     ]
    }
   ],
   "source": [
    "print('Векторизация...', )\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.integer)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.integer)\n",
    "\n",
    "\n",
    "# Ваш код здесь\n",
    "for i, seq in enumerate(sentences):\n",
    "    for j, token in enumerate(seq):\n",
    "        x[i,j,char_indices[token]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "        \n",
    "\n",
    "print('... Готово')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим, размерность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22007, 70, 61), (22007, 61))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Подготовка к генерации текста\n",
    "Создадим функцию `generating_text`, которая будет генерировать объекты на основании моделей:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generating_text(diversity, model):\n",
    "    print()\n",
    "    print('...Генерация текста. Температура: ', diversity)\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    sys.stdout.write(generated)\n",
    "    for i in range(700):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0] #Вектор вероятностей, полученный с помощью модели\n",
    "        next_index = sample(preds, diversity) # Выбираем индекс\n",
    "        next_char = indices_char[next_index] #Выбираем символ из словаря \n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Temperature. We can also play with the temperature of the Softmax during sampling. Decreasing the temperature from 1 to some lower number (e.g. 0.5) makes the RNN more confident, but also more conservative in its samples. Conversely, higher temperatures will give more diversity but at cost of more mistakes (e.g. spelling mistakes, etc). In particular, setting temperature very near zero will give the most likely thing that Paul Graham might say:\n",
    ">> “is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same”\n",
    "\n",
    "> looks like we’ve reached an infinite loop about startups.\n",
    "\n",
    "Источник: [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, GRU, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. VanilaRNN\n",
    "Создадим простую RNN с одним слоем из 128 нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/keleas/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 128)               24320     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 61)                7869      \n",
      "=================================================================\n",
      "Total params: 32,189\n",
      "Trainable params: 32,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/keleas/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17605 samples, validate on 4402 samples\n",
      "Epoch 1/20\n",
      "17605/17605 [==============================] - 8s 445us/step - loss: 3.6717 - val_loss: 3.5305\n",
      "Epoch 2/20\n",
      "17605/17605 [==============================] - 10s 578us/step - loss: 3.4212 - val_loss: 3.3776\n",
      "Epoch 3/20\n",
      "17605/17605 [==============================] - 12s 671us/step - loss: 3.0851 - val_loss: 3.0867\n",
      "Epoch 4/20\n",
      "17605/17605 [==============================] - 8s 473us/step - loss: 2.9948 - val_loss: 3.2440\n",
      "Epoch 5/20\n",
      "17605/17605 [==============================] - 11s 598us/step - loss: 2.9885 - val_loss: 2.9403\n",
      "Epoch 6/20\n",
      "17605/17605 [==============================] - 14s 815us/step - loss: 2.8811 - val_loss: 2.9355\n",
      "Epoch 7/20\n",
      "17605/17605 [==============================] - 11s 610us/step - loss: 2.8707 - val_loss: 2.9521\n",
      "Epoch 8/20\n",
      "17605/17605 [==============================] - 10s 565us/step - loss: 2.8665 - val_loss: 2.9181\n",
      "Epoch 9/20\n",
      "17605/17605 [==============================] - 10s 555us/step - loss: 2.8751 - val_loss: 2.9705\n",
      "Epoch 10/20\n",
      "17605/17605 [==============================] - 7s 419us/step - loss: 2.8764 - val_loss: 2.9870\n",
      "Epoch 11/20\n",
      "17605/17605 [==============================] - 11s 639us/step - loss: 2.8561 - val_loss: 2.9266\n",
      "Epoch 12/20\n",
      "17605/17605 [==============================] - 8s 435us/step - loss: 2.8251 - val_loss: 2.9852\n",
      "Epoch 13/20\n",
      "17605/17605 [==============================] - 8s 428us/step - loss: 2.8180 - val_loss: 2.8986\n",
      "Epoch 14/20\n",
      "17605/17605 [==============================] - 7s 408us/step - loss: 2.8132 - val_loss: 3.0491\n",
      "Epoch 15/20\n",
      "17605/17605 [==============================] - 8s 435us/step - loss: 2.8017 - val_loss: 2.9401\n",
      "Epoch 16/20\n",
      "17605/17605 [==============================] - 11s 602us/step - loss: 2.8468 - val_loss: 2.8850\n",
      "Epoch 17/20\n",
      "17605/17605 [==============================] - 8s 458us/step - loss: 2.7939 - val_loss: 2.8650\n",
      "Epoch 18/20\n",
      "17605/17605 [==============================] - 14s 808us/step - loss: 2.7840 - val_loss: 2.7615\n",
      "Epoch 19/20\n",
      "17605/17605 [==============================] - 13s 763us/step - loss: 2.7971 - val_loss: 2.9572\n",
      "Epoch 20/20\n",
      "17605/17605 [==============================] - 12s 690us/step - loss: 2.7841 - val_loss: 2.8907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18ff716d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=128,\n",
    "          epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сгенерируем текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...Генерация текста. Температура:  0.5\n",
      "емит правдивая хвала:\n",
      "кто славил марса и темиру\n",
      "и бранную повесил лиру                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keleas/anaconda3/envs/keras/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n"
     ]
    }
   ],
   "source": [
    "generating_text(0.5, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с параметром `diversity` и посмотрите как изменяется генерируемый текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Need more layers... \n",
    "Добавьте второй слой в нашу RNN, обучите и посмотрите на результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 256)               81408     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 61)                15677     \n",
      "=================================================================\n",
      "Total params: 97,085\n",
      "Trainable params: 97,085\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(256, input_shape=(maxlen, len(chars))))\n",
    "\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, batch_size=128,\n",
    "          epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generating_text(0.5, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте какой текст получается при генерации для разного параметра `diversity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generating_text(0.8, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generating_text(1.5, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Больше экспериментов\n",
    "Попробуйте различные варианты сетей: GRU и LSTM. Сравните результаты и выберите удачные примеры генерации текста. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 70, 128)           97280     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 61)                7869      \n",
      "=================================================================\n",
      "Total params: 236,733\n",
      "Trainable params: 236,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17605 samples, validate on 4402 samples\n",
      "Epoch 1/5\n",
      "17605/17605 [==============================] - 41s 2ms/step - loss: 3.3957 - val_loss: 3.3469\n",
      "Epoch 2/5\n",
      "17605/17605 [==============================] - 41s 2ms/step - loss: 3.3521 - val_loss: 3.4641\n",
      "Epoch 3/5\n",
      "17605/17605 [==============================] - 43s 2ms/step - loss: 3.3574 - val_loss: 3.3852\n",
      "Epoch 4/5\n",
      "17605/17605 [==============================] - 43s 2ms/step - loss: 3.3583 - val_loss: 3.4391\n",
      "Epoch 5/5\n",
      "11136/17605 [=================>............] - ETA: 14s - loss: 3.3594"
     ]
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=128,\n",
    "          epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...Генерация текста. Температура:  0.8\n",
      "ывало тешил ханов\n",
      "стихов гремучим жемчугом.\n",
      "\n",
      "на нити праздного веселья,\n",
      "ны лю, внем уж честьки росостые,\n",
      "взем с чут? моей надожик,\n",
      "друг как мого гружа прокучанья\n",
      "я в, подлость бериструут рескаел.\n",
      "и тет берспоего стун\n",
      "ей ролон забера темый\n",
      "на редостомпо устыл и чаляв,\n",
      "ком мое глобил муты , воценья\n",
      "меня в горша далан,\n",
      "своей горот шубный\n",
      "расной\n",
      "понька, бул ул всон сторлет савы,\n",
      "и твой ль перя, не ует половил.\n",
      "\n",
      "восториталь судькой поло снил\n",
      "не узавстим насможит, над вилиты,\n",
      "вотого веждет поленья и выл,\n",
      "смате сель тире полавый бор\n",
      "пырел поустал поросей восторши,\n",
      "ужа и бесто верской\n",
      "дороды утрыни сер,\n",
      "и лебя злил сторой ном,\n",
      "ут мине не лостенья\n",
      "и сыны гразной разна,\n",
      "вы пералу морк хологу волчавный небю\n",
      "е раззлоной,\n",
      "и берег в не  путь глеком зизоком\n",
      "кела гредил с тоб\n"
     ]
    }
   ],
   "source": [
    "generating_text(0.8, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
